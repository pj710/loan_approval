{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6fb378",
   "metadata": {},
   "source": [
    "# Feature Engineering - Applying EDA Learnings\n",
    "\n",
    "**Project**: Loan Approval Decision Support System  \n",
    "**Phase**: 3 - Feature Engineering  \n",
    "**Date**: February 14, 2026\n",
    "\n",
    "## Objectives\n",
    "\n",
    "This notebook applies insights from the EDA (Phase 2) to create predictive features for mortgage approval modeling:\n",
    "\n",
    "1. **Create Underwriting Metrics**: LTV, Loan-to-Income, Housing Expense Ratio\n",
    "2. **Engineer Risk Indicators**: DTI risk flags, combined risk scores\n",
    "3. **Geographic Features**: Target encoding for high-cardinality location features\n",
    "4. **Interaction Features**: DTI × LTV, Income × Location\n",
    "5. **Feature Selection**: Remove redundant/low-importance features\n",
    "6. **Final Preprocessing**: Scaling, train-test split preparation\n",
    "\n",
    "## Key EDA Insights Applied\n",
    "\n",
    "- ✅ **DTI is primary predictor**: Create 4-tier risk classification\n",
    "- ✅ **Co-borrower impact**: 92% approval vs 88% for solo applicants\n",
    "- ✅ **Geographic variation**: State-level approval rates vary 78-94%\n",
    "- ✅ **Income-Loan relationship**: Strong correlation (0.7+), create ratio features\n",
    "- ✅ **Age patterns**: Middle-aged applicants show highest approval rates\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51e62156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# IMPORT LIBRARIES\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, chi2\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Configure visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc63c7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "WORKING DIRECTORY VERIFICATION\n",
      "================================================================================\n",
      "Current working directory: /Users/josiahgordor/Desktop/DSPortfolio/Projects/loan_approval\n",
      "✅ Working directory set to project root\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SET WORKING DIRECTORY\n",
    "# ============================================================================\n",
    "import os\n",
    "\n",
    "# Set working directory to project root\n",
    "project_root = Path('/Users/josiahgordor/Desktop/DSPortfolio/Projects/loan_approval')\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"WORKING DIRECTORY VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"✅ Working directory set to project root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aee203e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: data/processed/loan_data_cleaned_v2.csv\n",
      "================================================================================\n",
      "DATA LOADED\n",
      "================================================================================\n",
      "Shape: 493,568 applications × 78 features\n",
      "Target: 89.60% approval rate\n",
      "Memory: 1794.02 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "unnamed:_0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "activity_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lei",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "derived_msa_md",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "state_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "county_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "census_tract",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "lien_status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total_units",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "conforming_loan_limit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "derived_ethnicity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "derived_race",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "derived_sex",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "action_taken",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "purchaser_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "preapproval",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reverse_mortgage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open_end_line_of_credit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "business_or_commercial_purpose",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "loan_amount",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "combined_loan_to_value_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "interest_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rate_spread",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hoepa_status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "total_loan_costs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_points_and_fees",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "origination_charges",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "discount_points",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lender_credits",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "loan_term",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prepayment_penalty_term",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "intro_rate_period",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "negative_amortization",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "interest_only_payment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "balloon_payment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "other_nonamortizing_features",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "property_value",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "manufactured_home_secured_property_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "manufactured_home_land_property_interest",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "income",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "debt_to_income_ratio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicant_credit_score_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "co_applicant_credit_score_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicant_ethnicity_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "co_applicant_ethnicity_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicant_ethnicity_observed",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "co_applicant_ethnicity_observed",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicant_race_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "co_applicant_race_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicant_race_observed",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "co_applicant_race_observed",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicant_sex",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "co_applicant_sex",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicant_sex_observed",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "co_applicant_sex_observed",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicant_age",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "co_applicant_age",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "applicant_age_above_62",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "submission_of_application",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "initially_payable_to_institution",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "aus_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "denial_reason_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tract_population",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tract_minority_population_percent",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ffiec_msa_md_median_family_income",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tract_to_msa_income_percentage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tract_owner_occupied_units",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tract_one_to_four_family_homes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tract_median_age_of_housing_units",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "loan_type_Federal Housing Administration insured (FHA)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "loan_type_USDA Rural Housing Service or Farm Service Agency guaranteed (RHS or FSA)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "loan_type_Veterans Affairs guaranteed (VA)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "construction_method_Site-Built",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dti_risk_flag",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "has_coborrower",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "race_minority",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hispanic",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a0c6b5ae-88ef-45d3-8a67-8d434539ed90",
       "rows": [
        [
         "0",
         "0",
         "2024",
         "549300DD4R4SYK5RAQ92",
         "34980",
         "0TN",
         "47043.0",
         "47043060502",
         "First Lien",
         "Single Family (1-4 Units)",
         "Conforming",
         "Not Hispanic or Latino",
         "White",
         "Joint",
         "Loan originated",
         "Fannie Mae",
         "Preapproval not requested",
         "Not a reverse mortgage",
         "Not an open-end line of credit",
         "Not primarily for a business or commercial purpose",
         "475000",
         "95.0",
         "7.562",
         "1.107",
         "Not a high-cost mortgage",
         "2971.2",
         "0.0",
         "1595.0",
         "0.0",
         "0.0",
         "360",
         "0",
         "0",
         "No negative amortization",
         "No interest-only payments",
         "No balloon payment",
         "No other non-fully amortizing features",
         "495000",
         "Not applicable",
         "Not applicable",
         "147000.0",
         "49",
         "Experian Fair Isaac",
         "Equifax Beacon 5.0",
         "Not Hispanic or Latino",
         "Not Hispanic or Latino",
         "Not collected on the basis of visual observation or surname",
         "Not collected on the basis of visual observation or surname",
         "White",
         "White",
         "Not collected on the basis of visual observation or surname",
         "Not collected on the basis of visual observation or surname",
         "Female",
         "Male",
         "Not collected on the basis of visual observation or surname",
         "Not collected on the basis of visual observation or surname",
         "45-54",
         "65-74",
         "No",
         "Submitted directly to your institution",
         "Initially payable to your institution",
         "Desktop Underwriter (DU)",
         "Not applicable",
         "3376",
         "18.72",
         "101700",
         "8.8",
         "762",
         "1137",
         "48",
         "1.0",
         "0",
         "0",
         "0",
         "1",
         "Elevated Risk",
         "True",
         "0",
         "0"
        ],
        [
         "1",
         "1",
         "2024",
         "549300DD4R4SYK5RAQ92",
         "99999",
         "0WV",
         "54109.0",
         "54109002902",
         "First Lien",
         "Single Family (1-4 Units)",
         "Conforming",
         "Not Hispanic or Latino",
         "White",
         "Joint",
         "Application denied",
         "Not applicable",
         "Preapproval not requested",
         "Not a reverse mortgage",
         "Not an open-end line of credit",
         "Not primarily for a business or commercial purpose",
         "125000",
         "101.0097",
         "0.0",
         "0.0",
         "Not applicable",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "360",
         "0",
         "0",
         "No negative amortization",
         "No interest-only payments",
         "No balloon payment",
         "No other non-fully amortizing features",
         "125000",
         "Not applicable",
         "Not applicable",
         "65000.0",
         "42",
         "Experian Fair Isaac",
         "FICO Risk Score Classic 04",
         "Not Hispanic or Latino",
         "Information not provided by applicant in mail, internet, or telephone application",
         "Not collected on the basis of visual observation or surname",
         "Not collected on the basis of visual observation or surname",
         "White",
         "Information not provided by applicant in mail, internet, or telephone application",
         "Not collected on the basis of visual observation or surname",
         "Not collected on the basis of visual observation or surname",
         "Male",
         "Female",
         "Not collected on the basis of visual observation or surname",
         "Not collected on the basis of visual observation or surname",
         "<25",
         "<25",
         "No",
         "Submitted directly to your institution",
         "Not applicable",
         "Not applicable",
         "Credit history",
         "3536",
         "3.22",
         "67600",
         "10.3",
         "1146",
         "1647",
         "38",
         "0.0",
         "0",
         "1",
         "0",
         "0",
         "Moderate Risk",
         "True",
         "0",
         "0"
        ],
        [
         "2",
         "3",
         "2024",
         "549300DD4R4SYK5RAQ92",
         "24660",
         "0NC",
         "37081.0",
         "37081017102",
         "First Lien",
         "Single Family (1-4 Units)",
         "Conforming",
         "Not Hispanic or Latino",
         "White",
         "Female",
         "Loan originated",
         "Fannie Mae",
         "Preapproval not requested",
         "Not a reverse mortgage",
         "Not an open-end line of credit",
         "Not primarily for a business or commercial purpose",
         "315000",
         "95.0",
         "7.437",
         "0.837",
         "Not a high-cost mortgage",
         "4136.54",
         "0.0",
         "1495.0",
         "0.0",
         "0.0",
         "360",
         "0",
         "0",
         "No negative amortization",
         "No interest-only payments",
         "No balloon payment",
         "No other non-fully amortizing features",
         "335000",
         "Not applicable",
         "Not applicable",
         "115000.0",
         "20%-<30%",
         "FICO Risk Score Classic 04",
         "No co-applicant",
         "Not Hispanic or Latino",
         "No co-applicant",
         "Not collected on the basis of visual observation or surname",
         "No co-applicant",
         "White",
         "No co-applicant",
         "Not collected on the basis of visual observation or surname",
         "No co-applicant",
         "Female",
         "No co-applicant",
         "Not collected on the basis of visual observation or surname",
         "No co-applicant",
         "55-64",
         "No co-applicant",
         "No",
         "Submitted directly to your institution",
         "Initially payable to your institution",
         "Desktop Underwriter (DU)",
         "Not applicable",
         "2366",
         "36.22",
         "80700",
         "10.5",
         "728",
         "943",
         "41",
         "1.0",
         "0",
         "0",
         "0",
         "1",
         "Low Risk",
         "True",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 78,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed:_0</th>\n",
       "      <th>activity_year</th>\n",
       "      <th>lei</th>\n",
       "      <th>derived_msa_md</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>lien_status</th>\n",
       "      <th>total_units</th>\n",
       "      <th>conforming_loan_limit</th>\n",
       "      <th>...</th>\n",
       "      <th>tract_median_age_of_housing_units</th>\n",
       "      <th>target</th>\n",
       "      <th>loan_type_Federal Housing Administration insured (FHA)</th>\n",
       "      <th>loan_type_USDA Rural Housing Service or Farm Service Agency guaranteed (RHS or FSA)</th>\n",
       "      <th>loan_type_Veterans Affairs guaranteed (VA)</th>\n",
       "      <th>construction_method_Site-Built</th>\n",
       "      <th>dti_risk_flag</th>\n",
       "      <th>has_coborrower</th>\n",
       "      <th>race_minority</th>\n",
       "      <th>hispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024</td>\n",
       "      <td>549300DD4R4SYK5RAQ92</td>\n",
       "      <td>34980</td>\n",
       "      <td>0TN</td>\n",
       "      <td>47043.0</td>\n",
       "      <td>47043060502</td>\n",
       "      <td>First Lien</td>\n",
       "      <td>Single Family (1-4 Units)</td>\n",
       "      <td>Conforming</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Elevated Risk</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024</td>\n",
       "      <td>549300DD4R4SYK5RAQ92</td>\n",
       "      <td>99999</td>\n",
       "      <td>0WV</td>\n",
       "      <td>54109.0</td>\n",
       "      <td>54109002902</td>\n",
       "      <td>First Lien</td>\n",
       "      <td>Single Family (1-4 Units)</td>\n",
       "      <td>Conforming</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Moderate Risk</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "      <td>549300DD4R4SYK5RAQ92</td>\n",
       "      <td>24660</td>\n",
       "      <td>0NC</td>\n",
       "      <td>37081.0</td>\n",
       "      <td>37081017102</td>\n",
       "      <td>First Lien</td>\n",
       "      <td>Single Family (1-4 Units)</td>\n",
       "      <td>Conforming</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Low Risk</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unnamed:_0  activity_year                   lei  derived_msa_md state_code  \\\n",
       "0           0           2024  549300DD4R4SYK5RAQ92           34980        0TN   \n",
       "1           1           2024  549300DD4R4SYK5RAQ92           99999        0WV   \n",
       "2           3           2024  549300DD4R4SYK5RAQ92           24660        0NC   \n",
       "\n",
       "  county_code  census_tract lien_status                total_units  \\\n",
       "0     47043.0   47043060502  First Lien  Single Family (1-4 Units)   \n",
       "1     54109.0   54109002902  First Lien  Single Family (1-4 Units)   \n",
       "2     37081.0   37081017102  First Lien  Single Family (1-4 Units)   \n",
       "\n",
       "  conforming_loan_limit  ... tract_median_age_of_housing_units target  \\\n",
       "0            Conforming  ...                                48    1.0   \n",
       "1            Conforming  ...                                38    0.0   \n",
       "2            Conforming  ...                                41    1.0   \n",
       "\n",
       "  loan_type_Federal Housing Administration insured (FHA)  \\\n",
       "0                                                  0       \n",
       "1                                                  0       \n",
       "2                                                  0       \n",
       "\n",
       "  loan_type_USDA Rural Housing Service or Farm Service Agency guaranteed (RHS or FSA)  \\\n",
       "0                                                  0                                    \n",
       "1                                                  1                                    \n",
       "2                                                  0                                    \n",
       "\n",
       "  loan_type_Veterans Affairs guaranteed (VA) construction_method_Site-Built  \\\n",
       "0                                          0                              1   \n",
       "1                                          0                              0   \n",
       "2                                          0                              1   \n",
       "\n",
       "   dti_risk_flag has_coborrower race_minority  hispanic  \n",
       "0  Elevated Risk           True             0         0  \n",
       "1  Moderate Risk           True             0         0  \n",
       "2       Low Risk           True             0         0  \n",
       "\n",
       "[3 rows x 78 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD CLEANED DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Load data from Phase 2 (Data Cleaning)\n",
    "data_path = Path('data/processed/loan_data_cleaned_v2.csv')\n",
    "\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATA LOADED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Shape: {df.shape[0]:,} applications × {df.shape[1]} features\")\n",
    "print(f\"Target: {df['target'].mean():.2%} approval rate\")\n",
    "print(f\"Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9ba26",
   "metadata": {},
   "source": [
    "## 1. Create Underwriting Metrics\n",
    "\n",
    "Based on EDA insights, we'll create key financial ratios used in mortgage underwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08b93d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREATING UNDERWRITING METRICS\n",
      "================================================================================\n",
      "✓ Loan-to-Income Ratio: Created (Median: 2.82)\n",
      "✓ Loan-to-Value Ratio (LTV): Created (Median: 90.2%)\n",
      "✓ Housing Expense Ratio: Created (Median: 0.174)\n",
      "✓ Loan Costs Ratio: Created (Median: 0.018)\n",
      "\n",
      "================================================================================\n",
      "NEW UNDERWRITING METRICS SUMMARY\n",
      "================================================================================\n",
      "       loan_to_income_ratio  loan_to_value_ratio  housing_expense_ratio  \\\n",
      "count         493568.000000        493568.000000          493568.000000   \n",
      "mean               2.865843            81.909155               0.165187   \n",
      "std                1.322241            22.953015               0.093725   \n",
      "min                0.000112             0.775194               0.000000   \n",
      "25%                2.037037            77.464789               0.111513   \n",
      "50%                2.824037            90.243902               0.174047   \n",
      "75%                3.646617            97.101449               0.229115   \n",
      "max               10.000000           150.000000               1.000000   \n",
      "\n",
      "       loan_costs_ratio  \n",
      "count     493568.000000  \n",
      "mean           0.021201  \n",
      "std            0.018196  \n",
      "min            0.000000  \n",
      "25%            0.007064  \n",
      "50%            0.017983  \n",
      "75%            0.032485  \n",
      "max            0.200000  \n",
      "\n",
      "================================================================================\n",
      "CORRELATION WITH APPROVAL (TARGET)\n",
      "================================================================================\n",
      "loan_to_income_ratio          : -0.1126\n",
      "loan_to_value_ratio           : -0.0128\n",
      "housing_expense_ratio         : +0.6006\n",
      "loan_costs_ratio              : +0.3970\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TASK 3.1: CREATE UNDERWRITING METRICS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CREATING UNDERWRITING METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create a copy for feature engineering\n",
    "df_fe = df.copy()\n",
    "\n",
    "# 1. Loan-to-Income Ratio (LTI)\n",
    "df_fe['loan_to_income_ratio'] = df_fe['loan_amount'] / df_fe['income']\n",
    "df_fe['loan_to_income_ratio'] = df_fe['loan_to_income_ratio'].clip(upper=10)  # Cap extreme values\n",
    "print(f\"✓ Loan-to-Income Ratio: Created (Median: {df_fe['loan_to_income_ratio'].median():.2f})\")\n",
    "\n",
    "# 2. Loan-to-Value Ratio (LTV)\n",
    "if 'property_value' in df_fe.columns:\n",
    "    df_fe['loan_to_value_ratio'] = (df_fe['loan_amount'] / df_fe['property_value']) * 100\n",
    "    df_fe['loan_to_value_ratio'] = df_fe['loan_to_value_ratio'].clip(upper=150)  # Cap at 150%\n",
    "    print(f\"✓ Loan-to-Value Ratio (LTV): Created (Median: {df_fe['loan_to_value_ratio'].median():.1f}%)\")\n",
    "else:\n",
    "    print(\"⚠ Property value not available - LTV not created\")\n",
    "\n",
    "# 3. Housing Expense Ratio\n",
    "if 'interest_rate' in df_fe.columns:\n",
    "    # Monthly payment estimate: P = L[c(1+c)^n]/[(1+c)^n-1]\n",
    "    # Simplified: use loan amount * interest rate / 12 / income as proxy\n",
    "    df_fe['housing_expense_ratio'] = (df_fe['loan_amount'] * df_fe['interest_rate'] / 100 / 12) / (df_fe['income'] / 12)\n",
    "    df_fe['housing_expense_ratio'] = df_fe['housing_expense_ratio'].clip(upper=1)  # Cap at 100%\n",
    "    print(f\"✓ Housing Expense Ratio: Created (Median: {df_fe['housing_expense_ratio'].median():.3f})\")\n",
    "else:\n",
    "    print(\"⚠ Interest rate not available - Housing Expense Ratio not created\")\n",
    "\n",
    "# 4. Total Loan Costs Ratio\n",
    "if 'total_loan_costs' in df_fe.columns:\n",
    "    df_fe['loan_costs_ratio'] = df_fe['total_loan_costs'] / df_fe['loan_amount']\n",
    "    df_fe['loan_costs_ratio'] = df_fe['loan_costs_ratio'].clip(upper=0.2)  # Cap at 20%\n",
    "    print(f\"✓ Loan Costs Ratio: Created (Median: {df_fe['loan_costs_ratio'].median():.3f})\")\n",
    "else:\n",
    "    print(\"⚠ Total loan costs not available - Loan Costs Ratio not created\")\n",
    "\n",
    "# Display summary statistics\n",
    "new_features = ['loan_to_income_ratio']\n",
    "if 'loan_to_value_ratio' in df_fe.columns:\n",
    "    new_features.append('loan_to_value_ratio')\n",
    "if 'housing_expense_ratio' in df_fe.columns:\n",
    "    new_features.append('housing_expense_ratio')\n",
    "if 'loan_costs_ratio' in df_fe.columns:\n",
    "    new_features.append('loan_costs_ratio')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEW UNDERWRITING METRICS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(df_fe[new_features].describe())\n",
    "\n",
    "# Check correlation with target\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION WITH APPROVAL (TARGET)\")\n",
    "print(\"=\"*80)\n",
    "for feat in new_features:\n",
    "    corr = df_fe[[feat, 'target']].corr().iloc[0, 1]\n",
    "    print(f\"{feat:30s}: {corr:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff3709",
   "metadata": {},
   "source": [
    "## 2. Create Risk Indicators\n",
    "\n",
    "Categorical risk flags based on lending industry standards and EDA insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c3f97ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREATING RISK INDICATORS\n",
      "================================================================================\n",
      "✓ DTI Risk Flag already exists or DTI not available\n",
      "\n",
      "✓ LTV Risk Flag created: 4 categories\n",
      "ltv_risk_flag\n",
      "Low Risk         160776\n",
      "High Risk        127416\n",
      "Elevated Risk    123131\n",
      "Moderate Risk     82245\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Income Bracket created: 6 categories\n",
      "income_bracket\n",
      "$100-150K    121194\n",
      "$150-250K     91948\n",
      "$75-100K      91700\n",
      "$50-75K       90185\n",
      ">$250K        52998\n",
      "<$50K         45543\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Loan Size Category created: 5 categories\n",
      "loan_size_category\n",
      "<$200K       125498\n",
      "$200-300K    117110\n",
      "$300-400K     96887\n",
      "$400-600K     92712\n",
      ">$600K        61361\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Combined Risk Score created (DTI + LTV average)\n",
      "   Range: 1.00 - 4.00\n",
      "   Mean: 2.36\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TASK 3.2: CREATE RISK INDICATORS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CREATING RISK INDICATORS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. DTI Risk Flag (from EDA - if not already present)\n",
    "if 'dti_risk_flag' not in df_fe.columns and 'debt_to_income_ratio' in df_fe.columns:\n",
    "    # Map DTI categories to risk levels (from EDA analysis)\n",
    "    dti_risk_mapping = {\n",
    "        '<20%': 'Low Risk',\n",
    "        '20%-<30%': 'Low Risk',\n",
    "        '30%-<36%': 'Moderate Risk',\n",
    "        '36': 'Moderate Risk',\n",
    "        '37': 'Moderate Risk',\n",
    "        '38': 'Moderate Risk',\n",
    "        '39': 'Moderate Risk',\n",
    "        '40': 'Moderate Risk',\n",
    "        '41': 'Moderate Risk',\n",
    "        '42': 'Moderate Risk',\n",
    "        '43': 'Moderate Risk',\n",
    "        '44': 'Elevated Risk',\n",
    "        '45': 'Elevated Risk',\n",
    "        '46': 'Elevated Risk',\n",
    "        '47': 'Elevated Risk',\n",
    "        '48': 'Elevated Risk',\n",
    "        '49': 'Elevated Risk',\n",
    "        '50%-60%': 'Elevated Risk',\n",
    "        '>60%': 'High Risk',\n",
    "        'Exempt': 'Unknown'\n",
    "    }\n",
    "    \n",
    "    df_fe['dti_risk_flag'] = df_fe['debt_to_income_ratio'].astype(str).map(dti_risk_mapping)\n",
    "    df_fe['dti_risk_flag'] = df_fe['dti_risk_flag'].fillna('Unknown')\n",
    "    print(f\"✓ DTI Risk Flag created: {df_fe['dti_risk_flag'].nunique()} categories\")\n",
    "    print(df_fe['dti_risk_flag'].value_counts())\n",
    "else:\n",
    "    print(\"✓ DTI Risk Flag already exists or DTI not available\")\n",
    "\n",
    "# 2. LTV Risk Flag\n",
    "if 'loan_to_value_ratio' in df_fe.columns:\n",
    "    def ltv_risk_category(ltv):\n",
    "        if pd.isna(ltv):\n",
    "            return 'Unknown'\n",
    "        elif ltv <= 80:\n",
    "            return 'Low Risk'\n",
    "        elif ltv <= 90:\n",
    "            return 'Moderate Risk'\n",
    "        elif ltv <= 97:\n",
    "            return 'Elevated Risk'\n",
    "        else:\n",
    "            return 'High Risk'\n",
    "    \n",
    "    df_fe['ltv_risk_flag'] = df_fe['loan_to_value_ratio'].apply(ltv_risk_category)\n",
    "    print(f\"\\n✓ LTV Risk Flag created: {df_fe['ltv_risk_flag'].nunique()} categories\")\n",
    "    print(df_fe['ltv_risk_flag'].value_counts())\n",
    "else:\n",
    "    print(\"\\n⚠ LTV not available - LTV Risk Flag not created\")\n",
    "\n",
    "# 3. Income Bracket (for stratification)\n",
    "if 'income' in df_fe.columns:\n",
    "    income_brackets = [0, 50000, 75000, 100000, 150000, 250000, np.inf]\n",
    "    income_labels = ['<$50K', '$50-75K', '$75-100K', '$100-150K', '$150-250K', '>$250K']\n",
    "    df_fe['income_bracket'] = pd.cut(df_fe['income'], bins=income_brackets, labels=income_labels)\n",
    "    print(f\"\\n✓ Income Bracket created: {df_fe['income_bracket'].nunique()} categories\")\n",
    "    print(df_fe['income_bracket'].value_counts())\n",
    "else:\n",
    "    print(\"\\n⚠ Income column not available - Income Bracket not created\")\n",
    "\n",
    "# 4. Loan Size Category\n",
    "loan_brackets = [0, 200000, 300000, 400000, 600000, np.inf]\n",
    "loan_labels = ['<$200K', '$200-300K', '$300-400K', '$400-600K', '>$600K']\n",
    "df_fe['loan_size_category'] = pd.cut(df_fe['loan_amount'], bins=loan_brackets, labels=loan_labels)\n",
    "print(f\"\\n✓ Loan Size Category created: {df_fe['loan_size_category'].nunique()} categories\")\n",
    "print(df_fe['loan_size_category'].value_counts())\n",
    "\n",
    "# 5. Combined Risk Score (DTI + LTV)\n",
    "if 'dti_risk_flag' in df_fe.columns and 'ltv_risk_flag' in df_fe.columns:\n",
    "    risk_score_map = {'Low Risk': 1, 'Moderate Risk': 2, 'Elevated Risk': 3, 'High Risk': 4, 'Unknown': 2.5}\n",
    "    \n",
    "    dti_score = df_fe['dti_risk_flag'].map(risk_score_map)\n",
    "    ltv_score = df_fe['ltv_risk_flag'].map(risk_score_map)\n",
    "    \n",
    "    df_fe['combined_risk_score'] = (dti_score + ltv_score) / 2\n",
    "    print(f\"\\n✓ Combined Risk Score created (DTI + LTV average)\")\n",
    "    print(f\"   Range: {df_fe['combined_risk_score'].min():.2f} - {df_fe['combined_risk_score'].max():.2f}\")\n",
    "    print(f\"   Mean: {df_fe['combined_risk_score'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd61bf1",
   "metadata": {},
   "source": [
    "## 3. Co-Borrower Features\n",
    "\n",
    "EDA showed co-borrower presence is a strong predictor (92% vs 88% approval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b3f245e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREATING CO-BORROWER FEATURES\n",
      "================================================================================\n",
      "✓ Co-borrower indicator created from co_applicant_ethnicity_1\n",
      "   Applications WITH co-borrower: 226,116 (45.8%)\n",
      "   Applications WITHOUT co-borrower: 267,452 (54.2%)\n",
      "   Approval rate WITH co-borrower: 91.29%\n",
      "   Approval rate WITHOUT co-borrower: 88.17%\n",
      "\n",
      "✓ Application Type created: 3 categories\n",
      "                   count      mean\n",
      "application_type                  \n",
      "Single - Female   180013  0.891597\n",
      "Single - Male     290814  0.903602\n",
      "Unknown            22741  0.832813\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CREATE CO-BORROWER FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CREATING CO-BORROWER FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Co-borrower presence indicator using co_applicant_ethnicity\n",
    "if 'co_applicant_ethnicity_1' in df_fe.columns:\n",
    "    # Check for 'No co-applicant' value to identify solo applications\n",
    "    df_fe['has_coborrower'] = (df_fe['co_applicant_ethnicity_1'] != 'No co-applicant').astype(int)\n",
    "    \n",
    "    # Count applications by co-borrower status\n",
    "    n_with_coborrower = (df_fe['has_coborrower'] == 1).sum()\n",
    "    n_without_coborrower = (df_fe['has_coborrower'] == 0).sum()\n",
    "    \n",
    "    print(f\"✓ Co-borrower indicator created from co_applicant_ethnicity_1\")\n",
    "    print(f\"   Applications WITH co-borrower: {n_with_coborrower:,} ({n_with_coborrower/len(df_fe):.1%})\")\n",
    "    print(f\"   Applications WITHOUT co-borrower: {n_without_coborrower:,} ({n_without_coborrower/len(df_fe):.1%})\")\n",
    "    \n",
    "    # Calculate approval rates by co-borrower status\n",
    "    if 'target' in df_fe.columns:\n",
    "        if n_with_coborrower > 0:\n",
    "            approval_with = df_fe[df_fe['has_coborrower']==1]['target'].mean()\n",
    "            print(f\"   Approval rate WITH co-borrower: {approval_with:.2%}\")\n",
    "        else:\n",
    "            print(f\"   Approval rate WITH co-borrower: N/A (no applications)\")\n",
    "            \n",
    "        if n_without_coborrower > 0:\n",
    "            approval_without = df_fe[df_fe['has_coborrower']==0]['target'].mean()\n",
    "            print(f\"   Approval rate WITHOUT co-borrower: {approval_without:.2%}\")\n",
    "        else:\n",
    "            print(f\"   Approval rate WITHOUT co-borrower: N/A (no applications)\")\n",
    "    else:\n",
    "        print(\"   ⚠ Warning: 'target' column not found - cannot calculate approval rates\")\n",
    "else:\n",
    "    print(\"⚠ Warning: 'co_applicant_ethnicity_1' column not found\")\n",
    "    print(\"   Cannot create co-borrower indicator - this feature will be missing\")\n",
    "    df_fe['has_coborrower'] = 0  # Default to no co-borrower if column missing\n",
    "\n",
    "# 2. Application type categorical\n",
    "if 'applicant_sex' in df_fe.columns:\n",
    "    df_fe['application_type'] = df_fe['applicant_sex'].map({\n",
    "        'Male': 'Single - Male',\n",
    "        'Female': 'Single - Female',\n",
    "        'Joint': 'Joint',\n",
    "        'Not Applicable': 'Joint'\n",
    "    })\n",
    "    df_fe['application_type'] = df_fe['application_type'].fillna('Unknown')\n",
    "    print(f\"\\n✓ Application Type created: {df_fe['application_type'].nunique()} categories\")\n",
    "    print(df_fe.groupby('application_type')['target'].agg(['count', 'mean']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cca520",
   "metadata": {},
   "source": [
    "## 4. Geographic Features & Target Encoding\n",
    "\n",
    "EDA showed significant geographic variation (78-94% approval by state). Use target encoding for high-cardinality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea5e29a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GEOGRAPHIC FEATURE ENGINEERING\n",
      "================================================================================\n",
      "✓ State approval rate encoded: 53 states\n",
      "   Range: 75.58% - 96.49%\n",
      "\n",
      "✓ County code: 3078 unique counties (will use target encoding in training)\n",
      "   County frequency encoded (baseline): Mean 1340 applications per county\n",
      "\n",
      "================================================================================\n",
      "NOTE: Proper target encoding will be applied during model training\n",
      "to avoid data leakage (encoding must be fit only on training data)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TASK 3.2: GEOGRAPHIC FEATURES & TARGET ENCODING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GEOGRAPHIC FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# We'll use target encoding for high-cardinality geographic features\n",
    "# Important: This should be done within cross-validation to avoid leakage\n",
    "# For now, we'll create the encoding structure\n",
    "\n",
    "# 1. State-level approval rate (low cardinality - safe to encode directly)\n",
    "if 'state_code' in df_fe.columns:\n",
    "    state_approval_rate = df_fe.groupby('state_code')['target'].mean()\n",
    "    df_fe['state_approval_rate'] = df_fe['state_code'].map(state_approval_rate)\n",
    "    print(f\"✓ State approval rate encoded: {df_fe['state_code'].nunique()} states\")\n",
    "    print(f\"   Range: {df_fe['state_approval_rate'].min():.2%} - {df_fe['state_approval_rate'].max():.2%}\")\n",
    "\n",
    "# 2. County-level features (high cardinality - mark for proper target encoding later)\n",
    "if 'county_code' in df_fe.columns:\n",
    "    n_counties = df_fe['county_code'].nunique()\n",
    "    print(f\"\\n✓ County code: {n_counties} unique counties (will use target encoding in training)\")\n",
    "    \n",
    "    # For now, create a frequency encoding as baseline\n",
    "    county_freq = df_fe['county_code'].value_counts()\n",
    "    df_fe['county_frequency'] = df_fe['county_code'].map(county_freq)\n",
    "    print(f\"   County frequency encoded (baseline): Mean {df_fe['county_frequency'].mean():.0f} applications per county\")\n",
    "\n",
    "# 3. MSA/MD features\n",
    "if 'msa_md' in df_fe.columns:\n",
    "    n_msa = df_fe['msa_md'].nunique()\n",
    "    print(f\"\\n✓ MSA/MD code: {n_msa} unique metropolitan areas\")\n",
    "    \n",
    "    # Frequency encoding\n",
    "    msa_freq = df_fe['msa_md'].value_counts()\n",
    "    df_fe['msa_frequency'] = df_fe['msa_md'].map(msa_freq)\n",
    "\n",
    "# 4. Census tract income deviation (if tract median income available)\n",
    "if 'tract_median_income' in df_fe.columns:\n",
    "    df_fe['income_vs_tract'] = df_fe['income'] / df_fe['tract_median_income']\n",
    "    df_fe['income_vs_tract'] = df_fe['income_vs_tract'].clip(upper=10)  # Cap extreme values\n",
    "    print(f\"\\n✓ Income vs Tract Median: Created (shows if applicant income is above/below area median)\")\n",
    "    print(f\"   Median ratio: {df_fe['income_vs_tract'].median():.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NOTE: Proper target encoding will be applied during model training\")\n",
    "print(\"to avoid data leakage (encoding must be fit only on training data)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bdba4c",
   "metadata": {},
   "source": [
    "## 5. Interaction Features\n",
    "\n",
    "Create interaction terms between important features identified in EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a4e02d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREATING INTERACTION FEATURES\n",
      "================================================================================\n",
      "✓ DTI × LTV interaction created\n",
      "   Median: 2.44\n",
      "\n",
      "✓ Income × Co-borrower interaction created\n",
      "\n",
      "✓ Loan Amount × Interest Rate interaction created\n",
      "\n",
      "✓ Age × Income interaction created\n",
      "\n",
      "================================================================================\n",
      "Total features after engineering: 94\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TASK 3.3: CREATE INTERACTION FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CREATING INTERACTION FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. DTI × LTV (Combined financial stress)\n",
    "if 'loan_to_income_ratio' in df_fe.columns and 'loan_to_value_ratio' in df_fe.columns:\n",
    "    df_fe['dti_ltv_interaction'] = df_fe['loan_to_income_ratio'] * df_fe['loan_to_value_ratio'] / 100\n",
    "    print(f\"✓ DTI × LTV interaction created\")\n",
    "    print(f\"   Median: {df_fe['dti_ltv_interaction'].median():.2f}\")\n",
    "\n",
    "# 2. Income × Has Co-borrower\n",
    "if 'has_coborrower' in df_fe.columns:\n",
    "    df_fe['income_coborrower_interaction'] = df_fe['income'] * df_fe['has_coborrower']\n",
    "    print(f\"\\n✓ Income × Co-borrower interaction created\")\n",
    "\n",
    "# 3. Loan Amount × Interest Rate (Payment burden)\n",
    "if 'interest_rate' in df_fe.columns:\n",
    "    df_fe['loan_rate_interaction'] = (df_fe['loan_amount'] / 1000) * df_fe['interest_rate']\n",
    "    print(f\"\\n✓ Loan Amount × Interest Rate interaction created\")\n",
    "\n",
    "# 4. Age × Income (Life-stage affordability)\n",
    "if 'applicant_age' in df_fe.columns:\n",
    "    # Convert age to numeric if it's categorical\n",
    "    if df_fe['applicant_age'].dtype == 'object':\n",
    "        age_mapping = {\n",
    "            '<25': 22,\n",
    "            '25-34': 30,\n",
    "            '35-44': 40,\n",
    "            '45-54': 50,\n",
    "            '55-64': 60,\n",
    "            '65-74': 70,\n",
    "            '>74': 78\n",
    "        }\n",
    "        df_fe['applicant_age_numeric'] = df_fe['applicant_age'].map(age_mapping)\n",
    "        df_fe['age_income_interaction'] = df_fe['applicant_age_numeric'] * (df_fe['income'] / 1000)\n",
    "    else:\n",
    "        df_fe['age_income_interaction'] = df_fe['applicant_age'] * (df_fe['income'] / 1000)\n",
    "    \n",
    "    print(f\"\\n✓ Age × Income interaction created\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Total features after engineering: {df_fe.shape[1]}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a2808",
   "metadata": {},
   "source": [
    "## 6. Feature Selection\n",
    "\n",
    "Remove redundant and low-importance features before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa2780ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE SELECTION\n",
      "================================================================================\n",
      "\n",
      "1. Checking for highly correlated features...\n",
      "   Found 1 highly correlated features: ['age_income_interaction']\n",
      "   Consider removing in final model to reduce multicollinearity\n",
      "\n",
      "2. Identifying protected attributes to EXCLUDE from modeling...\n",
      "   Found 18 protected attributes:\n",
      "   - derived_ethnicity\n",
      "   - derived_race\n",
      "   - derived_sex\n",
      "   - applicant_ethnicity_1\n",
      "   - co_applicant_ethnicity_1\n",
      "   - applicant_ethnicity_observed\n",
      "   - co_applicant_ethnicity_observed\n",
      "   - applicant_race_1\n",
      "   - co_applicant_race_1\n",
      "   - applicant_race_observed\n",
      "   - co_applicant_race_observed\n",
      "   - applicant_sex\n",
      "   - co_applicant_sex\n",
      "   - applicant_sex_observed\n",
      "   - co_applicant_sex_observed\n",
      "   - tract_minority_population_percent\n",
      "   - race_minority\n",
      "   - hispanic\n",
      "\n",
      "3. Categorizing features for modeling...\n",
      "   Engineered features: 15\n",
      "   Original features: 10\n",
      "\n",
      "   Total features for modeling: 25\n",
      "   Features excluded (protected): 18\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TASK 3.4: FEATURE SELECTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE SELECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Remove highly correlated features (>0.95)\n",
    "print(\"\\n1. Checking for highly correlated features...\")\n",
    "\n",
    "# Select only numeric columns for correlation analysis\n",
    "numeric_cols = df_fe.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Remove target from correlation analysis\n",
    "if 'target' in numeric_cols:\n",
    "    numeric_cols.remove('target')\n",
    "\n",
    "corr_matrix = df_fe[numeric_cols].corr().abs()\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find features with correlation > 0.95\n",
    "high_corr_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n",
    "\n",
    "if high_corr_features:\n",
    "    print(f\"   Found {len(high_corr_features)} highly correlated features: {high_corr_features}\")\n",
    "    print(f\"   Consider removing in final model to reduce multicollinearity\")\n",
    "else:\n",
    "    print(\"   ✓ No features with correlation > 0.95\")\n",
    "\n",
    "# 2. Identify features to EXCLUDE (protected attributes)\n",
    "print(\"\\n2. Identifying protected attributes to EXCLUDE from modeling...\")\n",
    "\n",
    "protected_features = []\n",
    "for col in df_fe.columns:\n",
    "    col_lower = col.lower()\n",
    "    if any(term in col_lower for term in ['race', 'ethnicity', 'sex', 'gender', 'minority', 'hispanic']):\n",
    "        if col != 'has_coborrower':  # Keep this as it's a legitimate feature\n",
    "            protected_features.append(col)\n",
    "\n",
    "print(f\"   Found {len(protected_features)} protected attributes:\")\n",
    "for feat in protected_features:\n",
    "    print(f\"   - {feat}\")\n",
    "\n",
    "# 3. Create lists of features for modeling\n",
    "print(\"\\n3. Categorizing features for modeling...\")\n",
    "\n",
    "# Engineered features to definitely include\n",
    "engineered_features = [\n",
    "    'loan_to_income_ratio', 'loan_to_value_ratio', 'housing_expense_ratio',\n",
    "    'loan_costs_ratio', 'dti_risk_flag', 'ltv_risk_flag', 'income_bracket',\n",
    "    'loan_size_category', 'combined_risk_score', 'has_coborrower',\n",
    "    'state_approval_rate', 'county_frequency', 'income_vs_tract',\n",
    "    'dti_ltv_interaction', 'income_coborrower_interaction', 'loan_rate_interaction'\n",
    "]\n",
    "\n",
    "# Keep only features that exist\n",
    "engineered_features = [f for f in engineered_features if f in df_fe.columns]\n",
    "\n",
    "print(f\"   Engineered features: {len(engineered_features)}\")\n",
    "\n",
    "# Original important features from EDA\n",
    "original_features = [\n",
    "    'income', 'loan_amount', 'property_value', 'interest_rate', 'loan_term',\n",
    "    'total_loan_costs', 'applicant_age', 'debt_to_income_ratio',\n",
    "    'state_code', 'county_code', 'msa_md'\n",
    "]\n",
    "original_features = [f for f in original_features if f in df_fe.columns]\n",
    "\n",
    "print(f\"   Original features: {len(original_features)}\")\n",
    "\n",
    "# Create feature list for modeling\n",
    "modeling_features = list(set(engineered_features + original_features))\n",
    "modeling_features = [f for f in modeling_features if f not in protected_features]\n",
    "\n",
    "print(f\"\\n   Total features for modeling: {len(modeling_features)}\")\n",
    "print(f\"   Features excluded (protected): {len(protected_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374a254",
   "metadata": {},
   "source": [
    "## 7. Final Data Preparation\n",
    "\n",
    "Prepare data for train-test split and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "830deaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENCODING CATEGORICAL VARIABLES\n",
      "================================================================================\n",
      "\n",
      "Categorical features to encode: 8\n",
      "  - county_code: 3078 unique values\n",
      "  - debt_to_income_ratio: 19 unique values\n",
      "  - loan_size_category: 5 unique values\n",
      "  - income_bracket: 6 unique values\n",
      "  - ltv_risk_flag: 4 unique values\n",
      "  - dti_risk_flag: 5 unique values\n",
      "  - applicant_age: 8 unique values\n",
      "  - state_code: 53 unique values\n",
      "\n",
      "1. One-hot encoding 5 low-cardinality features...\n",
      "   ✓ One-hot encoding complete\n",
      "   New shape: (493568, 112)\n",
      "\n",
      "2. High-cardinality features for target encoding: 3\n",
      "  - county_code: 3078 categories\n",
      "  - debt_to_income_ratio: 19 categories\n",
      "  - state_code: 53 categories\n",
      "\n",
      "   Note: Target encoding will be applied during model training to prevent leakage\n",
      "\n",
      "================================================================================\n",
      "Final dataset shape: 493,568 rows × 112 columns\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TASK 3.5: ENCODE CATEGORICAL VARIABLES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create a copy for final processing\n",
    "df_final = df_fe.copy()\n",
    "\n",
    "# 1. Identify categorical features\n",
    "categorical_features = df_final[modeling_features].select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"\\nCategorical features to encode: {len(categorical_features)}\")\n",
    "for feat in categorical_features:\n",
    "    print(f\"  - {feat}: {df_final[feat].nunique()} unique values\")\n",
    "\n",
    "# 2. One-hot encode low-cardinality categoricals (<10 categories)\n",
    "low_cardinality_cats = [col for col in categorical_features if df_final[col].nunique() < 10]\n",
    "print(f\"\\n1. One-hot encoding {len(low_cardinality_cats)} low-cardinality features...\")\n",
    "\n",
    "if low_cardinality_cats:\n",
    "    df_encoded = pd.get_dummies(df_final, columns=low_cardinality_cats, prefix=low_cardinality_cats, drop_first=True)\n",
    "    print(f\"   ✓ One-hot encoding complete\")\n",
    "    print(f\"   New shape: {df_encoded.shape}\")\n",
    "else:\n",
    "    df_encoded = df_final.copy()\n",
    "    print(f\"   No low-cardinality features to encode\")\n",
    "\n",
    "# 3. High-cardinality features (>10 categories) - save for target encoding during training\n",
    "high_cardinality_cats = [col for col in categorical_features if df_final[col].nunique() >= 10]\n",
    "print(f\"\\n2. High-cardinality features for target encoding: {len(high_cardinality_cats)}\")\n",
    "for feat in high_cardinality_cats:\n",
    "    print(f\"  - {feat}: {df_final[feat].nunique()} categories\")\n",
    "\n",
    "print(\"\\n   Note: Target encoding will be applied during model training to prevent leakage\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Final dataset shape: {df_encoded.shape[0]:,} rows × {df_encoded.shape[1]} columns\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64b7f7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "APPLYING FEATURE HASHING FOR HIGH-CARDINALITY FEATURES\n",
      "================================================================================\n",
      "\n",
      "✓ State code hashed: 53 states → 16 hash features\n",
      "   Hash distribution: min=-1.00, max=1.00\n",
      "   Hasher saved for inference\n",
      "\n",
      "✓ DTI hashed: 19 unique values → 5 hash features\n",
      "   Hash distribution: min=-1.00, max=1.00\n",
      "\n",
      "✓ County code hashed: 3078 counties → 32 hash features\n",
      "   Hash distribution: min=-1.00, max=1.00\n",
      "   Hasher saved for inference\n",
      "\n",
      "================================================================================\n",
      "Hashed features: ['state_code', 'debt_to_income_ratio', 'county_code']\n",
      "Final dataset shape: (493568, 115)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "import joblib\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE HASHING FOR HIGH-CARDINALITY FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"APPLYING FEATURE HASHING FOR HIGH-CARDINALITY FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Dictionary to store hashers for inference\n",
    "hashing_artifacts = {}\n",
    "\n",
    "# 1. Hash state_code\n",
    "if 'state_code' in df_encoded.columns:\n",
    "    # Create feature hasher with 16 features (2^4 = 16 buckets)\n",
    "    state_hasher = FeatureHasher(n_features=16, input_type='string')\n",
    "    \n",
    "    # Convert state_code to list of strings for hasher\n",
    "    state_hashed = state_hasher.transform(df_encoded[['state_code']].astype(str).values).toarray()\n",
    "    df_encoded['state_code_hashed'] = state_hashed.sum(axis=1)  # Aggregate hash values\n",
    "    \n",
    "    print(f\"\\n✓ State code hashed: {df_encoded['state_code'].nunique()} states → 16 hash features\")\n",
    "    print(f\"   Hash distribution: min={df_encoded['state_code_hashed'].min():.2f}, max={df_encoded['state_code_hashed'].max():.2f}\")\n",
    "    print(f\"   Hasher saved for inference\")\n",
    "    hashing_artifacts['state_code'] = {\n",
    "        'hasher': state_hasher,\n",
    "        'n_features': 16,\n",
    "        'input_type': 'string',\n",
    "        'output_column': 'state_code_hashed',\n",
    "        'original_cardinality': df_encoded['state_code'].nunique()\n",
    "    }\n",
    "    \n",
    "if 'debt_to_income_ratio' in df_encoded.columns:\n",
    "    dti_hasher = FeatureHasher(n_features=5, input_type='string')\n",
    "    dti_hashed = dti_hasher.transform(df_encoded[['debt_to_income_ratio']].astype(str).values).toarray()\n",
    "    df_encoded['dti_hashed'] = dti_hashed.sum(axis=1)\n",
    "    print(f\"\\n✓ DTI hashed: {df_encoded['debt_to_income_ratio'].nunique()} unique values → 5 hash features\")\n",
    "    print(f\"   Hash distribution: min={df_encoded['dti_hashed'].min():.2f}, max={df_encoded['dti_hashed'].max():.2f}\")\n",
    "    hashing_artifacts['debt_to_income_ratio'] = {\n",
    "        'hasher': dti_hasher,\n",
    "        'n_features': 5,\n",
    "        'input_type': 'string',\n",
    "        'output_column': 'dti_hashed',\n",
    "        'original_cardinality': df_encoded['debt_to_income_ratio'].nunique()\n",
    "    }\n",
    "\n",
    "# 2. Hash county_code (if present and high cardinality)\n",
    "if 'county_code' in df_encoded.columns and df_encoded['county_code'].nunique() > 100:\n",
    "    county_hasher = FeatureHasher(n_features=32, input_type='string')\n",
    "    \n",
    "    county_hashed = county_hasher.transform(df_encoded[['county_code']].astype(str).values).toarray()\n",
    "    df_encoded['county_code_hashed'] = county_hashed.sum(axis=1)\n",
    "    \n",
    "    print(f\"\\n✓ County code hashed: {df_encoded['county_code'].nunique()} counties → 32 hash features\")\n",
    "    print(f\"   Hash distribution: min={df_encoded['county_code_hashed'].min():.2f}, max={df_encoded['county_code_hashed'].max():.2f}\")\n",
    "    print(f\"   Hasher saved for inference\")\n",
    "    hashing_artifacts['county_code'] = {\n",
    "        'hasher': county_hasher,\n",
    "        'n_features': 32,\n",
    "        'input_type': 'string',\n",
    "        'output_column': 'county_code_hashed',\n",
    "        'original_cardinality': df_encoded['county_code'].nunique()\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Hashed features: {list(hashing_artifacts.keys())}\")\n",
    "print(f\"Final dataset shape: {df_encoded.shape}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a39260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "UPDATING FEATURE LISTS AFTER ENCODING & HASHING\n",
      "================================================================================\n",
      "\n",
      "1. Total columns after encoding: 115\n",
      "2. Columns to exclude: 30\n",
      "3. Modeling features after encoding: 90\n",
      "4. Updated engineered features: 39\n",
      "   - One-hot encoded features: 25\n",
      "   - Hashed features: 3\n",
      "\n",
      "   Sample one-hot encoded features:\n",
      "     - applicant_age_above_62\n",
      "     - applicant_age_numeric\n",
      "     - loan_size_category_$200-300K\n",
      "     - loan_size_category_$300-400K\n",
      "     - loan_size_category_$400-600K\n",
      "     ... and 20 more\n",
      "\n",
      "   Hashed features created:\n",
      "     - state_code_hashed\n",
      "     - dti_hashed\n",
      "     - county_code_hashed\n",
      "\n",
      "================================================================================\n",
      "✅ Feature lists updated for modeling\n",
      "   Modeling Features: 90\n",
      "   Engineered Features: 39\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# UPDATE FEATURE LISTS AFTER ENCODING & HASHING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"UPDATING FEATURE LISTS AFTER ENCODING & HASHING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Get all columns after encoding and hashing\n",
    "all_columns = df_encoded.columns.tolist()\n",
    "\n",
    "# 2. Identify columns to exclude from modeling\n",
    "exclude_from_modeling = set()\n",
    "\n",
    "# Add target\n",
    "if 'target' in all_columns:\n",
    "    exclude_from_modeling.add('target')\n",
    "\n",
    "# Add protected features\n",
    "exclude_from_modeling.update(protected_features)\n",
    "\n",
    "# Add original categorical columns that were one-hot encoded\n",
    "exclude_from_modeling.update(low_cardinality_cats)\n",
    "\n",
    "# Add original high-cardinality features that were hashed (keep only hashed versions)\n",
    "for feature in hashing_artifacts.keys():\n",
    "    if feature in all_columns:\n",
    "        exclude_from_modeling.add(feature)\n",
    "\n",
    "# Add any ID or metadata columns\n",
    "metadata_cols = ['activity_year', 'lei', 'action_taken']\n",
    "for col in metadata_cols:\n",
    "    if col in all_columns:\n",
    "        exclude_from_modeling.add(col)\n",
    "\n",
    "print(f\"\\n1. Total columns after encoding: {len(all_columns)}\")\n",
    "print(f\"2. Columns to exclude: {len(exclude_from_modeling)}\")\n",
    "\n",
    "# 3. Update modeling_features to include actual encoded columns\n",
    "modeling_features = [col for col in all_columns if col not in exclude_from_modeling]\n",
    "\n",
    "print(f\"3. Modeling features after encoding: {len(modeling_features)}\")\n",
    "\n",
    "# 4. Identify new encoded features (one-hot encoded columns)\n",
    "encoded_feature_cols = [col for col in all_columns \n",
    "                        if any(col.startswith(f\"{cat}_\") for cat in low_cardinality_cats)]\n",
    "\n",
    "# 5. Identify hashed feature columns\n",
    "hashed_feature_cols = [col for col in all_columns \n",
    "                       if col.endswith('_hashed')]\n",
    "\n",
    "# 6. Update engineered_features to include all transformations\n",
    "engineered_features_updated = []\n",
    "\n",
    "# Keep original engineered features that are still present\n",
    "for feat in engineered_features:\n",
    "    if feat in all_columns and feat not in low_cardinality_cats:\n",
    "        engineered_features_updated.append(feat)\n",
    "\n",
    "# Add one-hot encoded features\n",
    "engineered_features_updated.extend(encoded_feature_cols)\n",
    "\n",
    "# Add hashed features\n",
    "engineered_features_updated.extend(hashed_feature_cols)\n",
    "\n",
    "# Remove duplicates\n",
    "engineered_features = sorted(list(set(engineered_features_updated)))\n",
    "\n",
    "print(f\"4. Updated engineered features: {len(engineered_features)}\")\n",
    "print(f\"   - One-hot encoded features: {len(encoded_feature_cols)}\")\n",
    "print(f\"   - Hashed features: {len(hashed_feature_cols)}\")\n",
    "\n",
    "# Display sample of encoded features\n",
    "if encoded_feature_cols:\n",
    "    print(f\"\\n   Sample one-hot encoded features:\")\n",
    "    for feat in encoded_feature_cols[:5]:\n",
    "        print(f\"     - {feat}\")\n",
    "    if len(encoded_feature_cols) > 5:\n",
    "        print(f\"     ... and {len(encoded_feature_cols) - 5} more\")\n",
    "\n",
    "if hashed_feature_cols:\n",
    "    print(f\"\\n   Hashed features created:\")\n",
    "    for feat in hashed_feature_cols:\n",
    "        print(f\"     - {feat}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"✅ Feature lists updated for modeling\")\n",
    "print(f\"   Modeling Features: {len(modeling_features)}\")\n",
    "print(f\"   Engineered Features: {len(engineered_features)}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dcc85d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING FEATURE-ENGINEERED DATA\n",
      "================================================================================\n",
      "\n",
      "✅ Feature-engineered data saved to: data/processed/feature_engineered_data.csv\n",
      "   Shape: 493,568 rows × 115 columns\n",
      "   Size: 695.52 MB\n",
      "\n",
      "✅ Feature engineering info saved to: data/processed/feature_engineering_info.json\n",
      "✅ Feature hashing artifacts saved to: data/processed/hashing_artifacts.pkl\n",
      "✅ Hashing configuration saved to: data/processed/hashing_config.json\n",
      "\n",
      "   To use during inference:\n",
      "  >>> import joblib\n",
      "  >>> hashers = joblib.load('hashing_artifacts.pkl')\n",
      "  >>> state_hasher = hashers['state_code']['hasher']\n",
      "  >>> hashed_values = state_hasher.transform(new_data[['state_code']].astype(str).values).toarray()\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SAVE FEATURE-ENGINEERED DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING FEATURE-ENGINEERED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save to processed directory\n",
    "output_path = Path('data/processed/feature_engineered_data.csv')\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save full dataset\n",
    "df_encoded.to_csv(output_path, index=False)\n",
    "print(f\"\\n✅ Feature-engineered data saved to: {output_path}\")\n",
    "print(f\"   Shape: {df_encoded.shape[0]:,} rows × {df_encoded.shape[1]} columns\")\n",
    "print(f\"   Size: {output_path.stat().st_size / 1024**2:.2f} MB\")\n",
    "\n",
    "# Save feature names for reference\n",
    "feature_info = {\n",
    "    'total_features': df_encoded.shape[1],\n",
    "    'engineered_features': engineered_features,\n",
    "    'original_features': original_features,\n",
    "    'protected_features': protected_features,\n",
    "    'high_cardinality_features': high_cardinality_cats,\n",
    "    'modeling_features': modeling_features\n",
    "}\n",
    "\n",
    "import json\n",
    "feature_info_path = output_path.parent / 'feature_engineering_info.json'\n",
    "with open(feature_info_path, 'w') as f:\n",
    "    # Convert non-serializable objects to lists\n",
    "    serializable_info = {k: list(v) if isinstance(v, (list, set)) else v for k, v in feature_info.items()}\n",
    "    json.dump(serializable_info, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Feature engineering info saved to: {feature_info_path}\")\n",
    "\n",
    "# Save hashing artifacts for inference\n",
    "if 'hashing_artifacts' in locals() and hashing_artifacts:\n",
    "    hashing_info_path = output_path.parent / 'hashing_artifacts.pkl'\n",
    "    joblib.dump(hashing_artifacts, hashing_info_path)\n",
    "    print(f\"✅ Feature hashing artifacts saved to: {hashing_info_path}\")\n",
    "    \n",
    "    # Save human-readable hashing config\n",
    "    hashing_config = {\n",
    "        feature: {\n",
    "            'n_features': info['n_features'],\n",
    "            'input_type': info['input_type'],\n",
    "            'output_column': info['output_column'],\n",
    "            'original_cardinality': info['original_cardinality']\n",
    "        }\n",
    "        for feature, info in hashing_artifacts.items()\n",
    "    }\n",
    "    \n",
    "    hashing_config_path = output_path.parent / 'hashing_config.json'\n",
    "    with open(hashing_config_path, 'w') as f:\n",
    "        json.dump(hashing_config, f, indent=2)\n",
    "    print(f\"✅ Hashing configuration saved to: {hashing_config_path}\")\n",
    "    print(f\"\\n   To use during inference:\")\n",
    "    print(f\"  >>> import joblib\")\n",
    "    print(f\"  >>> hashers = joblib.load('{hashing_info_path.name}')\")\n",
    "    print(f\"  >>> state_hasher = hashers['state_code']['hasher']\")\n",
    "    print(f\"  >>> hashed_values = state_hasher.transform(new_data[['state_code']].astype(str).values).toarray()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf2bbc",
   "metadata": {},
   "source": [
    "## 8. Feature Engineering Summary\n",
    "\n",
    "Review of all feature engineering steps completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d52d334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE ENGINEERING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✅ PHASE 3 COMPLETE: Feature Engineering\n",
      "\n",
      "================================================================================\n",
      "TASKS COMPLETED:\n",
      "================================================================================\n",
      "\n",
      "1. ✓ Underwriting Metrics Created:\n",
      "   - Loan-to-Income Ratio\n",
      "   - Loan-to-Value Ratio (LTV)\n",
      "   - Housing Expense Ratio\n",
      "   - Loan Costs Ratio\n",
      "\n",
      "2. ✓ Risk Indicators Created:\n",
      "   - DTI Risk Flag (4-tier)\n",
      "   - LTV Risk Flag (4-tier)\n",
      "   - Income Bracket (6 categories)\n",
      "   - Loan Size Category (5 categories)\n",
      "   - Combined Risk Score (DTI + LTV)\n",
      "\n",
      "3. ✓ Co-Borrower Features Created:\n",
      "   - Co-borrower presence indicator\n",
      "   - Application type (Single vs Joint)\n",
      "\n",
      "4. ✓ Geographic Features Created:\n",
      "   - State approval rate encoding\n",
      "   - County frequency encoding\n",
      "   - Income vs Tract Median ratio\n",
      "\n",
      "5. ✓ Interaction Features Created:\n",
      "   - DTI × LTV interaction\n",
      "   - Income × Co-borrower interaction\n",
      "   - Loan Amount × Interest Rate interaction\n",
      "   - Age × Income interaction\n",
      "\n",
      "6. ✓ Feature Selection Completed:\n",
      "   - 90 features selected for modeling\n",
      "   - 18 protected attributes excluded\n",
      "   - 3 high-cardinality features marked for target encoding\n",
      "\n",
      "7. ✓ Categorical Encoding:\n",
      "   - 5 features one-hot encoded\n",
      "   - 3 features prepared for target encoding\n",
      "\n",
      "================================================================================\n",
      "NEXT STEPS (Phase 4):\n",
      "================================================================================\n",
      "\n",
      "1. Train-Test-Validation Split (70-15-15)\n",
      "2. Apply target encoding on training data only\n",
      "3. Feature scaling/normalization\n",
      "4. Baseline model training (Logistic Regression)\n",
      "5. Advanced models (XGBoost, Random Forest, Neural Network)\n",
      "6. Model evaluation and comparison\n",
      "7. Fairness auditing on test set\n",
      "\n",
      "================================================================================\n",
      "Dataset ready for modeling: data/processed/feature_engineered_data.csv\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FEATURE ENGINEERING SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n✅ PHASE 3 COMPLETE: Feature Engineering\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASKS COMPLETED:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. ✓ Underwriting Metrics Created:\")\n",
    "print(\"   - Loan-to-Income Ratio\")\n",
    "print(\"   - Loan-to-Value Ratio (LTV)\")\n",
    "print(\"   - Housing Expense Ratio\")\n",
    "print(\"   - Loan Costs Ratio\")\n",
    "\n",
    "print(\"\\n2. ✓ Risk Indicators Created:\")\n",
    "print(\"   - DTI Risk Flag (4-tier)\")\n",
    "print(\"   - LTV Risk Flag (4-tier)\")\n",
    "print(\"   - Income Bracket (6 categories)\")\n",
    "print(\"   - Loan Size Category (5 categories)\")\n",
    "print(\"   - Combined Risk Score (DTI + LTV)\")\n",
    "\n",
    "print(\"\\n3. ✓ Co-Borrower Features Created:\")\n",
    "print(\"   - Co-borrower presence indicator\")\n",
    "print(\"   - Application type (Single vs Joint)\")\n",
    "\n",
    "print(\"\\n4. ✓ Geographic Features Created:\")\n",
    "print(\"   - State approval rate encoding\")\n",
    "print(\"   - County frequency encoding\")\n",
    "print(\"   - Income vs Tract Median ratio\")\n",
    "\n",
    "print(\"\\n5. ✓ Interaction Features Created:\")\n",
    "print(\"   - DTI × LTV interaction\")\n",
    "print(\"   - Income × Co-borrower interaction\")\n",
    "print(\"   - Loan Amount × Interest Rate interaction\")\n",
    "print(\"   - Age × Income interaction\")\n",
    "\n",
    "print(\"\\n6. ✓ Feature Selection Completed:\")\n",
    "print(f\"   - {len(modeling_features)} features selected for modeling\")\n",
    "print(f\"   - {len(protected_features)} protected attributes excluded\")\n",
    "print(f\"   - {len(high_cardinality_cats)} high-cardinality features marked for target encoding\")\n",
    "\n",
    "print(\"\\n7. ✓ Categorical Encoding:\")\n",
    "print(f\"   - {len(low_cardinality_cats)} features one-hot encoded\")\n",
    "print(f\"   - {len(high_cardinality_cats)} features prepared for target encoding\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEXT STEPS (Phase 4):\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. Train-Test-Validation Split (70-15-15)\")\n",
    "print(\"2. Apply target encoding on training data only\")\n",
    "print(\"3. Feature scaling/normalization\")\n",
    "print(\"4. Baseline model training (Logistic Regression)\")\n",
    "print(\"5. Advanced models (XGBoost, Random Forest, Neural Network)\")\n",
    "print(\"6. Model evaluation and comparison\")\n",
    "print(\"7. Fairness auditing on test set\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Dataset ready for modeling: {output_path}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds4b_101p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
